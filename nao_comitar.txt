oÉ possível somente realizar int() para que nao precise reescrever todos os operadores em uma classe de scheduler, na hora de realizar criar o rank

operator const volatile int() const volatile { return _prority; }

LLF vai virar um rank dessa lista. (Ranked)

attributo Doubly_Linked_Ordered provavelmente 

main precisa ter priority 0

--------------

Fila única - repassar chunks da fila que possuam mesma prioridade pra frente pra trás

--- não obrigatoriamente precisa ser dinamico


// Thread::init
// Devemos ter uma solução forte para que no thread::init() tenhamos certeza que main e idle sejam criados antes de qualquer interrupcao
// new no Thread::init invoca o construtor do objeto
// new (endereço do hardware) - (objeto)
// diferença do kmalloc -> lib diferente (vamos fazer um alocador parecido com c++)
// inline nao joga o construtor em algum endereço de memoria, isso é metaprogramação


// Eu quero sempre executar aquela thread que tem menos tempo pra executar até o deadline (o objetivo e nao perder nenhum deadline)

// Calcular folga no dispatch dentro do if de (charge)

A cada iteração calculamos o slack time para restaurar o timer

// É só ver a diferença do elapsed pro período

---------------------------------------------

É possível somente realizar int() para que nao precise reescrever todos os operadores em uma classe de scheduler, na hora de realizar criar o rank

operator const volatile int() const volatile { return _prority; }

LLF vai virar um rank dessa lista. (Ranked)

attributo Doubly_Linked_Ordered provavelmente 

main precisa ter priority 0

--------------

Fila única - repassar chunks da fila que possuam mesma prioridade pra frente pra trás

--- não obrigatoriamente precisa ser dinamico

-------------------

FCFS constructor is defined elsewhere because we need to know the priority of the thread which is the elapsed time. Lower the time, the older the thread is and higher its prority is

The "..." in the constructor parameter of one of the scheduler's classes is to discard the rest of the parameters which will not be used

The empty constructor is used to initialize the objects variables

-------------

When the quantum is exausted we need to yield the running thread so it can check if it will be changed or it will continue executing. This is timed trait

-------------------------

The capability of the thread to change its prority over the execution time of the program is defined in the dynamic trait

-------------

We will never have overflow in Alarm::elapsed because the if the time could be overflown in compilation it will fail the compilation process

-------------

Scheduling_Queue: biblioteca de escalonamento para nível de usuários

Charge -> cobrar da tarefa - a super tarefa main n deveria ser cobrada

O unico momento que n é cobrado o charge é quando ela chama o pass

----------

Ready queue doesnt exist anymore, we use the scheduler to it can find the running (which is the chosen one)

---

Who defines the preemptive is the criterion (which will be created (the llf one))

-----

Escalonadores não colocam nada pra rodar, apenas ordenar a fila

o resume nao faz a thread acordar

----

É para nunca mais precisarmos ir na classe threads para alterar algo

---

Trocar a prioridade não reordena a fila

----------

`_link.rank(Criterion(c));`
_link.rank(int a)
Criterion(c) -> Criterion::int()

This is done so the c priority type value is passed so Criterion can be created with all its variables, and used as a parameter by being implicitly converted using int() operator we created in it.

This HAS to be changed in `void Thread::priority(const Criterion & e`

-----------
TU TA DE BRINCADEIRA

Recalcular a prioridade não faz diferença? - o tempo passou 

Resp: faz diferença sim.... 

-------

Escalonador não troca o estado, escalonador é uma "capa" em cima da fila


-----

Reeschedule chooses (another). The thread chosen can be the same thread as before so it can continue running.

It only returns the new (or not) chosen thread

----
Criterion has to be passed. The priority int() operator has to be implemented

---

Load é um método de baixo nível que vai ler do registradores

JESUS CRISTO

------

Switch_context dá push e pop em uma pilha de contextos da classe, porque?

--------

Salvar o contexto na pilha 

AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA



----------

Locais onde a prioridade tem que ser atualizada 

scheduler.h -> Policty Traits

-------

Um único ponto de captura/atualização no charge -> cobrar o quantum

--------------------

Alarm que nos escolhemos pra aquele thread chama interrupcções que chamam o update para o próxima thread que vai ser escalonada

Quero fazer o update de todos

Overload do operador update  


??????????????????????????????????????????????? mlk que porra é essa

-------

Todos façam dinâmico - deve ser atualizado

Vou atualizar a prioridade de todos depois da criação

----

Há uma maneira de modelar o edf sem executar os updates

---

// Inicia a thread, aloca a pilha e insere a thread no escalonador.

void Thread::constructor_prologue(unsigned int stack_size);

  

// Finaliza a configuração da thread, configurando seu estado e, se necessário, fazendo-a elegível para execução imediata.

void Thread::constructor_epilogue(Log_Addr entry, unsigned int stack_size);

  

// Destrutor da thread, remove a thread do escalonador e libera recursos alocados.

Thread::~Thread();

  

// Define a prioridade da thread, possivelmente causando uma reordenação no escalonador.

void Thread::priority(const Criterion & c);

  

// Espera pela conclusão de outra thread.

int Thread::join();

  

// Passa voluntariamente o controle para a próxima thread pronta a ser executada.

void Thread::pass();

  

// Suspende a execução da thread atual, removendo-a da fila de execução até que seja explicitamente retomada.

void Thread::suspend();

  

// Retoma a execução de uma thread previamente suspensa, reinserindo-a na fila de execução.

void Thread::resume();

  

// Cede a execução para outra thread, permitindo a execução de outras tarefas.

void Thread::yield();

  

// Termina a execução da thread atual e seleciona a próxima thread a ser executada.

void Thread::exit(int status);

  

// Coloca a thread atual em espera, baseado em uma condição específica.

void Thread::sleep(Queue \* q);

  

// Desperta uma única thread que está esperando em uma condição específica.

void Thread::wakeup(Queue \* q);

  

// Desperta todas as threads que estão esperando em uma condição específica.

void Thread::wakeup_all(Queue \* q);

  

// Força uma nova escolha de thread a ser executada, baseando-se na prioridade.

void Thread::reschedule();

  

// Fatia de tempo para a preempção, usada para controlar quanto tempo uma thread pode executar antes de ceder a CPU.

void Thread::time_slicer(IC::Interrupt_Id i);

  

// Troca o contexto da thread atual pela próxima thread escolhida para execução.

void Thread::dispatch(Thread _ prev, Thread _ next, bool charge);

  

// Executa enquanto houver mais de uma thread ativa, mantendo o sistema operacional em funcionamento.

int Thread::idle();

  

Métodos a Serem Adaptados

reschedule() e time_slicer(): Estes são os principais pontos onde o escalonamento toma uma decisão sobre qual thread deve executar a seguir. Antes de escolher a próxima thread a ser executada, você deve assegurar que as prioridades estejam atualizadas para refletir as demandas atuais. Portanto, chamar um método de atualização de prioridades aqui garante que a escolha da próxima thread a ser executada considere as prioridades mais recentes.

  

sleep() e wakeup()/wakeup_all(): Quando uma thread é posta em espera ou despertada, isso pode alterar significativamente a sua urgência ou deadlines. Integrar a atualização de prioridades após essas ações pode ajudar a manter o escalonador alinhado com as necessidades reais das threads.

  

Thread::constructor_epilogue(): Ao finalizar a criação de uma thread, estabelecer sua prioridade inicial com base na lógica de LLF pode ser uma boa prática, especialmente para sistemas que necessitam de um escalonamento sensível ao tempo desde o início.

  

Implementação da Atualização de Prioridade

Integrar Atualizações de Prioridade: Em reschedule() e time_slicer(), antes de escolher a próxima thread, invoque um método, por exemplo, update_all_priorities(), que percorra todas as threads aptas e atualize suas prioridades com base na laxidade ou slack time atual.

  

void Thread::reschedule() {

lock();

update*all_priorities(); // Atualiza a prioridade de todas as threads

Thread * prev = running();

Thread \_ next = \_scheduler.choose();

dispatch(prev, next);

unlock();

}

  

Atualização de Prioridade em Eventos de Sono e Despertar: Em sleep() e wakeup()/wakeup_all(), considere chamar update_priority() para a thread em questão, ajustando sua prioridade individualmente conforme seu estado muda.

  

void Thread::wakeup(Queue _ q) {

lock();

if(!q->empty()) {

Thread _ t = q->remove()->object();

t->update_priority(); // Atualiza a prioridade da thread específica

t->\_state = READY;

\_scheduler.resume(t);

}

if(preemptive) reschedule();

unlock();

}

-------------



deadline *pode* ser menor ou maior que o periodo. (fodase)

**p = d** 

Static LLF na verdade é Laxity Monotic.

Como os períodos são diferentes, pode ser que a thread que no início tem a maior laxidade quando chega-se no final do seu deadline, pode ter a maior laxidade e deveria ser colocada como prioridade

update priority
_priority_ = deadline + start (antigo) - capacity - Alarm::elapsed() * 1000

update
-> Se o update priority é chamado com o ended execution false quer dizer que ele perdeu o deadline e a proridade dele vai ser a maior possível


update:
-> se terminou a execução então reseta o alarme e seta o boolean pra false
-> executa o update prioridade 

Eles tão atualizando a capacity dinamicamente, por isso precisam guardar o inicio (_start) da execuçao. O start usado é o guardado da ultima vez  

---

O mais importante é ordenar por uma política na reta dos numeros naturais. nao precisa estar semanticamente correto

-------

Implementar um mecanismo de impedir a inversão de prioridades - ceiling

Dentro do P1 precisa-se depurar o problema do timer para entrar com confia na questão do multicore 

Priority Ceiling:

Você tem dois processos: jantar dos filosofos com prioridades diferentes, o filosofo de baixa prioridade tem o lock e está executando e o de alta não pode preemptar pois está com o lock e não podemos dar rollback

Uma seção crítica de baixa prioridade está segurando uma seção crítica de alta proridade -> solução: aumentar a proridade do processo de baixa prioridade pro teto para que ele consiga terminar a execução e liberar o recurso -> teto absoluto: maior int possível -> 2^64 -1


Importante: Na hora que a thread de baixa prioridade sair da seção crítica, precisamos baixar a prioridade dela para a prioridade original 

Podemos executar a mudança de proridade no próprio semaforo? Sim ->
Synchronizer pode fazer pros dois (mutex e semaforo) e vai ficar "bonitinho"


processador tem 4 camadas (normalmente)

a de mais baixo nível pode tudo. 

Usuário
Supervisor -> aqui que estamos trabalhando, aplicações estão aqui também
Hypervisor
Machine

Máquina que estamos trabalhando tem 5 cores 

Estamos trabalhando com uma isa que é heterogeneo 

No processador E, qualquer código com memória, que escrever na MMU, estiver no modo S, vai dar pau se for executado no processador E

E = rv64ic
U = RV64ICAM

Maquinas com mesmo iso mesmo processador mesma visao de memoria são chamados de heterogenea 

Quando bootamos, desligamos o E. Para não dar problemas Além disso renomeamos os cores: 1 -> 0, 2 -> 1.....

Não é o mesmo ISA

Epos está enganando a arquitetura, pois estamos renomeando os cores. Estou usando o registrador TP pra marcar os processadores sem contar o E (desativado).

O QEMU está emulando todos os 5 processadores, o EPOS desativa um, o gdb vê todos

comando é thread pra trocar de processador no gdb

Baixar o compilador na página do moodle - pra possuir o gdb que funciona normalmente 

CPU é ligada na 1C e seus fios são ligados para os possíveis dispositivos de interrupção. o 1C é ligado no CPU por um sinal INT

CPU ---- CLINT (1C) ---- PLIC ---Interrupção externa (não usamos) --- Disco, Redes... 
			|
			Interrupção de timer
			Compara um contador com um timer, quando o timer bate com o contador (real time clock - usado pela cpu). A cada tick somamos o tempo no contador para que o proximo tick seja calculado. A cada interrupção jogamos o contador += tempo


			Machine time -> precisamos do modo S | 


MTI = 7
STI = 5 

Por isso que não podemos dar override pelo S. Temos que criar um mini hypervisor

Todas as interrupções tem um registrador de máscara. No CLINT é Interrupt Enable tem o bit pro MTI

Temos que esperar "um pouquinho" para que possamos saber que o valor está certo

Limpar o bit dizendo assim "já atendemos essa interrupção"

Como dizer que ja atnedamos: Reprogramos o comparador, esperamos alguns nano segundos para ver que a comparação está errada

Não só apaga como também reprograma o timer

Machine vai ter que ter uma API para podermos dizer que atendemos a interrupção para que possamos limpar o bit. "Um nano sistema operacional só pra cuidar do timer"

Coisas que são feitas na maquina que o SO nao gostaria que existisse. O setup é um codigo que pega uma maquina bare metal e coloca de uma forma um pouquinho mais educada 

parametros do setup ali pra setar funcoes na mao

- used = eu irei usar a funcao entao na delete ela
- naked = nao quero criar um stack frame pra essa funcao (se eu quiser eu irei criar na mão)

// Desabilita o core 0, core E cagado
if (CPU::mhartid() == 0) {
	CPU::halt();
}

// m -> machine
// Desliga as interrupções
CPU::mstatusc(CPU::MIE);

// Guardar no registrador tp o id da cpu
CPU::tp(CPU::mhartid() - 1)

// Setar o stack pointer - literalmente a terceira instrução qeu eu to executando na maquina
CPU::sp

// 
Machine::clear_bss();

//setando o gerenciador de interrupções - direct mando todas as interrupções pro mesmo lugar
CPU::mtvec

STI fodase porque tem numero diferente

Delegar todas as exceções
CPU::medeleg(0xf1ff);


mepc -> machine exception program counter

--- Todo o resto do código é em modo supervisor

setup_m2s -> "mini nano hypervisor"
-> pega o código da funcao e coloca no inicio ou no final da memoria (depois digo que aquele endereço não existe)

ISA é de 32 bits, comprimido

CPU::mcause() -> numero da interrupção

Se é um interrupção do modo machine reseto o timer -> somo o tick no comparador
seto a STI pra disparar

linko a STI caso eu tenha feito uma chamada de sistema. Exceções do riscv nao incrementam o PC, preciso fazer na mão

EXC_ENVS -> chamada entre níveis

mret volto pro nivel anterior

Commitei o erro

Erro:
- Salvando registrador relativo a algo que nao existe
- Stack aumentando descontraladamente
- Chamadas pra um nivel que nao param de acontecer nunca

Linha 271 de setup_sifive_u.cc

----------------------------

A thread running (alta prioridade) tenta buscar um recurso que uma thread de prioridade baixa alocou, que está na fila de ready. Ela nunca vai rodar porque é prioridade baixa. Temos que aumentar a prioridade da thread que alocou o recurso pro teto para que ela seja escalonada, execute e libere o recurso

Criar um teste para provocar inversão de prioridade

------------

Bug do hardware - 70% da nota é o bug de hardware do timer do riscV

Não consigo explicar o valor do EPC porque a propria arquitetura ta salvando e esse valor tá corrompido

Usem o timer, usem o forwarder de machine to supervisor para determinar dinamicamente o limite (onde que é safe colocar um timer)

Imprimindo os valores do stack pointer do EPC para que não seja possível com tentativa e erro

----
Devagar o clock -> stack pointer sobe e desce (comportamento normal)

Subindo o clock -> stack pointer aumenta descontroladamente

-----------
Quando interrupções acontecem demasiadamente, o sp só cresce

----

EPC é um registrador especial (Exception Program Counter) e ele vai ter valores absurdos (que nem o guto soube explicar o pq)

A própria arquitetura salva ele, como que ele ultrapassa o lugar dele na memória?

Ligo o debug só no IC e na Thread - Desligar o debug no resto - precisamos ler o stack pointer - temos nível classe e no debug. Podemos desligar o debug na super classe e ligar nas subclasse

Ver o registrador SP e EPC

------

GDB não se dá run - Qual o programa que o gdb tá depurando? o qemu.

O gdb já tá running, precisamos dar step/continue para ver os passos

----

`make APPLICATION=hello clean all debug`

all - compila sem o menos -g e chama o gdb
clean - compila com -g e adiciona meta informação

Ele dá bypass no qemu, pois o gdb tá depurando o qemu

Teste do gdb cagado:

- Info threads não mostra nada, info register não mostra nada

`thread`
`info thread`
`info register`

mstatus muito importante pra entender a passagem das interrupções

`display /i $pc`

microbootloader 

`stepi`

_entry -> estamos rodando no EPOS


-- QEMU

ctrl a c m

info cpus

cpu 1

info mem

-- criando breakpoint

b Setup::call_next()

info mem agora tem o mapeamento (agora consigo setar breakpoints para endereços lógicos)

info registers mtvec stvec -> registradores que apontam pros handlers de interrupção

`b *$mtvec` breakpoint no registrador do endereço lógico do tratador de interrupção 

c -> continue

x /32i $pc

Log apenas o que tem a ver com MMU e Interrupções (interrupções são async=1)
se é uma exceção ele salva o valor da memória q eu tentei acessar. Como são interrupções o tval é 0

Isso é o log do qemu, 

4, 5 mtimer pra 1 stimer a capacidade do processador foi extrapolada e o erro é mostrado

se for stimer -> mtimer

Cada vez que o registrador n fizer sentido - instrução nao 

Sistema não tá verificando o stackoverflow, entao as variaveis estao tendo seus valores mudados sem que as instruções alterassem esses valores                     

---


-- Preciso fazer isso hoje

Criar/usar teste pra fazer o debug, mudando tick no traits, ver onde é guardado o EPC ou se é necessário mudar algo pra conseguir printar o EPC. Mas é o SP que vai crescer descaradamente

Print no dispatcher da interrupção para logar o que está acontecendo

------------


A configuracao do tamanho do tick é hoje estatica, transformar pra dinamica é a saída mais dificil possivel

Não tem timestamp preciso

Uma interrupção no modo machine - configuram o modo supervisor e com isso passam as calls pro supervisor, deveria ser uma orderm de M -> S -> M -> S

Tem a ver com interrupção e troca de contexto - criar teste pra fazer várias switch_context

Trocar velocidade do TICK, provavelmente no traits. Isso vai gerar instabilidade nessas situações

"Diminuir a aceleração do tempo"

"Façam o código de vcs como vcs acham que deve"

include/machine/riscv_ic.h

physical handler ->

`static void entry() __attribute((naked, aligned(4)))

naked -> não monte o stack frame, vou me virar sozinho / Criamos a função em C (ao invés de assembly) e por isso não queremos nada a mais 

porque é feito desse jeito?

mtime -> contando o tempo

setup faz um teste, se o cara colocar a frequência acima do recomendado (?)

environment call -> ecall
`ecall proibido comprimir, pode sempre somar 4 ao PC`

Não estamos checando se deveriamos somar 4 ou 2 bytes ao EPC quando a exceção acontece

mtime é único no multicore - mtimecmp é o que existe em todos

-- ajustar aligned(4) pra 32 bits -> 8 bytes aligned(8)

ultimo bit do mcause diz se é uma interrupção ou exceção

------------

IC::entry chamou dispatch (quero ver que horas eram), passou pro dispatch de novo, quantos nanossegundos passaram? A aplicação não está com tempo para rodar. esse processo de propagação não pode gastar mais de 1% da máquina

Fazer cálculo em cima (regra de três) disso para descobrir range do time e saber quanto que a aplicação deveria ter de tempo (99%) e adicionar o teste no setup. Se o valor for fora desse range, o setup deve impedir a execução ou mandar um warning

Chegando próximo do limite, lançar warning, passou do limite dar erro

1 - MTI - interrupção machine do timer
2 - Machine propaga interrupção do timer pro Supervisor, e seta o MIP.STI (IC::Entry). 
Supervisor faz uma ECall pro Machine, dando clear no MIP.STI

----

Fazer um profiling de um conjunto de instruções para ver as interrupções em cada máquina. Em cada máquina vai ter valores diferentes

Criar teste de profiler para que possamos entender o valor

Criar um algoritmo para fazer um profiling - Não é necessário mandar o código, mas sim os logs que foram utilizados

ifdef pra executar somente quando estamos realizando o profiling